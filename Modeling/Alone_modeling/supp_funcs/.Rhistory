est_paras_wide <- dcast(est_paras, subid+appearance ~ block, value.var = names(est_paras)[4:9])
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, value.var = names(est_paras)[4])
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, value.var = names(est_paras)[4:5])
View(est_paras_wide)
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, value.var = names(est_paras)[5])
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, value.var = names(est_paras)[5:6])
names(est_paras)[5:6]
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, fun=sum,value.var = names(est_paras)[5:6])
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, fun.aggregate=sum,value.var = names(est_paras)[5:6])
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, fun.aggregate=sum,value.var = c( "Par_Sure","Par_Pro","Par_Random","FishZ_Sure","FishZ_Pro","FishZ_Random"))
suppressMessages(library('data.table')) # must before reshape2
suppressMessages(library("dplyr"))
suppressMessages(library("reshape2"))
suppressMessages(library("gridExtra"))
suppressMessages(library("ggpubr"))
suppressMessages(library("tm"))
suppressMessages(library("RColorBrewer"))
suppressMessages(library('psych'))
suppressMessages(library("sjPlot")) #for plotting estimates in the lm.
suppressMessages(library("ggplot2"))
rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library('data.table')) # must before reshape2
suppressMessages(library("dplyr"))
suppressMessages(library("reshape2"))
suppressMessages(library("gridExtra"))
suppressMessages(library("ggpubr"))
suppressMessages(library("tm"))
suppressMessages(library("RColorBrewer"))
suppressMessages(library('psych'))
suppressMessages(library("sjPlot")) #for plotting estimates in the lm.
suppressMessages(library("ggplot2"))
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, fun.aggregate=sum,value.var = c( "Par_Sure","Par_Pro","Par_Random","FishZ_Sure","FishZ_Pro","FishZ_Random"))
rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library('data.table')) # must before reshape2
suppressMessages(library("dplyr"))
suppressMessages(library("reshape2"))
suppressMessages(library("gridExtra"))
suppressMessages(library("ggpubr"))
suppressMessages(library("tm"))
suppressMessages(library("RColorBrewer"))
suppressMessages(library('psych'))
suppressMessages(library("sjPlot")) #for plotting estimates in the lm.
suppressMessages(library("ggplot2"))
#calculating dishonest
re_shape <- function(df,sub_n,Trial_n,Block_n,varname){
new_df <- data.frame('subid'=rep("NULL",sub_n*Trial_n*Block_n),'appearance'=rep(NaN,sub_n*Trial_n*Block_n),'block'=rep(NaN,sub_n*Trial_n*Block_n),'trial'=rep(NaN,sub_n*Trial_n*Block_n),'Sure'=rep(NaN,sub_n*Trial_n*Block_n),'Prob'=rep(NaN,sub_n*Trial_n*Block_n),'Random'=rep(NaN,sub_n*Trial_n*Block_n))
new_df$subid <- as.character(new_df$subid)
for (mm in 1:sub_n){
sub_name                                                      <- levels(df$subid)[mm]
for (kk in 1:Block_n){
df1                                                         <- df[df$subid==sub_name & df$block==kk & df$prob==1,] #sure
df2                                                         <- df[df$subid==sub_name & df$block==kk & df$prob==2,] #pro
df3                                                         <- df[df$subid==sub_name & df$block==kk & df$prob==3,] #random
for (nn in 1:Trial_n){
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'subid']          <- sub_name
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'appearance']     <- df1$appearance[1]
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'block']          <- kk
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'trial']          <- nn
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'Sure']           <- df1[nn,varname]
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'Pro']            <- df2[nn,varname]
new_df[((mm-1)*Block_n+kk-1)*Trial_n+nn,'Random']         <- df3[nn,varname]
}
}
}
new_df$subid                                                    <- factor(new_df$subid)
return(new_df)
}
# estimate parameters
para_est <- function(df,sub_n,block_n){
para_df <- data.frame('subid'=rep("NULL",sub_n*block_n),'appearance'=rep("NULL",sub_n*block_n),'block'=rep(NaN,sub_n*block_n),'Par_Sure'=rep(NaN,sub_n*block_n),'Par_Pro'=rep(NaN,sub_n*block_n),'Par_Random'=rep(NaN,sub_n*block_n),'FishZ_Sure'=rep(NaN,sub_n*block_n),'FishZ_Pro'=rep(NaN,sub_n*block_n),'FishZ_Random'=rep(NaN,sub_n*block_n))
para_df$subid <- as.character(para_df$subid)
for (mm in 1:sub_n){
for (nn in 1:block_n){
sub_name                                       <- levels(df$subid)[mm]
para_df[(mm-1)*block_n+nn,'subid']             <- sub_name
new_df                                         <- df[df$subid==sub_name & df$block==nn,]
para_df[(mm-1)*block_n+nn,'appearance']        <- new_df$appearance[1]
para_df[(mm-1)*block_n+nn,'block']             <- nn
lms1                                           <- lm(Sure ~trial,data=new_df,na.action=na.exclude)
para_df[(mm-1)*block_n+nn,'Par_Sure']          <- as.numeric(lms1$coefficients['trial'])
r1                                             <- cor(new_df[,'trial'], new_df[,'Sure'],method="pearson",use="complete.obs")
para_df[(mm-1)*block_n+nn,'FishZ_Sure']        <- 0.5*(log(1+r1)-log(1-r1)) # transferring to Fisher Z
lms2                                           <- lm(Pro ~trial,data=new_df,na.action=na.exclude)
para_df[(mm-1)*block_n+nn,'Par_Pro']               <- as.numeric(lms2$coefficients['trial'])
r2                                             <- cor(new_df[,'trial'], new_df[,'Pro'],method="pearson",use="complete.obs")
para_df[(mm-1)*block_n+nn,'FishZ_Pro']         <- 0.5*(log(1+r2)-log(1-r2)) # transferring to Fisher Z
lms3                                           <- lm(Random ~trial,data=new_df,na.action=na.exclude)
para_df[(mm-1)*block_n+nn,'Par_Random']            <- as.numeric(lms3$coefficients['trial'])
r3                                             <- cor(new_df[,'trial'], new_df[,'Random'],method="pearson",use="complete.obs")
para_df[(mm-1)*block_n+nn,'FishZ_Random']      <- 0.5*(log(1+r3)-log(1-r3)) # transferring to Fisher Z
}
}
return(para_df)
}
#avg across subjects and trials
avg_score <- function(df,sub_n,varname){
para_df <- data.frame('subid'=rep("NULL",sub_n),'Appearance'=rep(NaN,sub_n),'Sure_bin1'=rep(NaN,sub_n),'Pro_bin1'=rep(NaN,sub_n),'Random_bin1'=rep(NaN,sub_n),'Sure_bin2'=rep(NaN,sub_n),'Pro_bin2'=rep(NaN,sub_n),'Random_bin2'=rep(NaN,sub_n))
para_df$subid <- as.character(para_df$subid)
for (mm in 1:sub_n){
sub_name <- levels(df$subid)[mm]
para_df[mm,'subid'] <- sub_name
new_df <- df[df$subid==sub_name,]
para_df[mm,'Appearance']    <- new_df$appearance[1]
para_df[mm,'Sure_bin1']     <- mean(new_df[new_df$prob==1 & new_df$bin==1,varname],na.rm=TRUE)
para_df[mm,'Pro_bin1']      <- mean(new_df[new_df$prob==2 & new_df$bin==1,varname],na.rm=TRUE)
para_df[mm,'Random_bin1']   <- mean(new_df[new_df$prob==3 & new_df$bin==1,varname],na.rm=TRUE)
para_df[mm,'Sure_bin2']     <- mean(new_df[new_df$prob==1 & new_df$bin==2,varname],na.rm=TRUE)
para_df[mm,'Pro_bin2']      <- mean(new_df[new_df$prob==2 & new_df$bin==2,varname],na.rm=TRUE)
para_df[mm,'Random_bin2']   <- mean(new_df[new_df$prob==3 & new_df$bin==2,varname],na.rm=TRUE)
}
return(para_df)
}
#avg for each trial
avg_score2 <- function(df,block_n,trial_n){
para_df <- data.frame('block'=rep(NaN,trial_n*block_n),'trial'=rep(NaN,trial_n*block_n),'Sure_avg'=rep(NaN,trial_n*block_n),'Pro_avg'=rep(NaN,trial_n*block_n),'Random_avg'=rep(NaN,trial_n*block_n),'Sure_se'=rep(NaN,trial_n*block_n),'Pro_se'=rep(NaN,trial_n*block_n),'Random_se'=rep(NaN,trial_n*block_n))
for (nn in 1:block_n){
for (mm in 1:trial_n){
para_df[(nn-1)*trial_n+mm,'block']                    <- nn
para_df[(nn-1)*trial_n+mm,'trial']                    <- mm
new_df                                                <- df[df$trial==mm & df$block==nn,]
para_df[(nn-1)*trial_n+mm,'Sure_avg']                 <- mean(new_df[,'Sure'],na.rm=TRUE)
para_df[(nn-1)*trial_n+mm,'Pro_avg']                  <- mean(new_df[,'Pro'],na.rm=TRUE)
para_df[(nn-1)*trial_n+mm,'Random_avg']               <- mean(new_df[,'Random'],na.rm=TRUE)
para_df[(nn-1)*trial_n+mm,'Sure_se']                  <- sd(new_df[,'Sure'],na.rm=TRUE)/sqrt(sum(!is.na(new_df$Sure)))
para_df[(nn-1)*trial_n+mm,'Pro_se']                   <- sd(new_df[,'Pro'],na.rm=TRUE)/sqrt(sum(!is.na(new_df$Pro)))
para_df[(nn-1)*trial_n+mm,'Random_se']                <- sd(new_df[,'Random'],na.rm=TRUE)/sqrt(sum(!is.na(new_df$Random)))
}
}
return(para_df)
}
#comparing correlation for alone and other conditions, for the average ACC data.
#https://f-santos.gitlab.io/2020-04-01-comparing-correlation-coefficients.html
diff_corr <- function(df,indices) {
df      <- df[indices, ]
cor1    <- cor(df[,'Trial_alone'], df[,'ACC_alone'],method="pearson")
cor2    <- cor(df[,'Trial_other'], df[,'ACC_other'],method="pearson")
return(cor2 - cor1)
}
compcorr <- function(df1,df2,block_n,varname){
para_df <- data.frame('block'=rep(NaN,block_n),'corr_alone'=rep(NaN,block_n),'corr_other'=rep(NaN,block_n),'lower_ci'=rep(NaN,block_n),'upper_ci'=rep(NaN,block_n),'sig'=rep(NaN,block_n))
for (nn in 1:block_n){
para_df[nn,'block']                    <- nn
new_df1                                <- df1[df1$block==nn,c('trial',varname)]
new_df2                                <- df2[df2$block==nn,c('trial',varname)]
comb_df                                <- cbind(new_df1,new_df2)
names(comb_df)                         <- c('Trial_alone','ACC_alone','Trial_other','ACC_other')
para_df[nn,'corr_alone']               <- cor(new_df1[,'trial'], new_df1[,varname],method="pearson")
para_df[nn,'corr_other']               <- cor(new_df2[,'trial'], new_df2[,varname],method="pearson")
## Then apply a bootstrap procedure with 5000 draws:
set.seed(2020)
res_boot <- boot(data = comb_df,
R = 5000,
statistic = diff_corr,
stype = "i")
ci                                    <- boot.ci(res_boot, type = "perc", conf = 0.95)
para_df[nn,'lower_ci']                <- ci$percent[4]
para_df[nn,'upper_ci']                <- ci$percent[5]
para_df[nn,'sig']                     <- as.integer((ci$percent[5]*ci$percent[4])>=0) #on the same side.
}
return(para_df)
}
raw_data               <- read.csv(file="all_data.csv",head=TRUE)
data_df                <- raw_data
data_df$subid          <- factor(data_df$subid)
sub_n                  <- length(levels(data_df$subid))
sub_name               <- as.character(levels(data_df$subid))
Block_n                 <- 5
Trial_n                 <- 50
ACC_data                <- re_shape(data_df,sub_n,Trial_n,Block_n,'ACC')
est_paras <- para_est(ACC_data,sub_n,Block_n)
est_paras_wide <- dcast(est_paras, subid+appearance ~ block, fun.aggregate=sum,value.var = c( "Par_Sure","Par_Pro","Par_Random","FishZ_Sure","FishZ_Pro","FishZ_Random"))
plot(rnorm(100),rnorm(100))
plot(rnorm(100),rnorm(100))
citation(“lme4”)
citation('lme4')
citation()
pkgs_CRAN <- c("MCMCglmm","blme",
"pbkrtest","coda","aods3","bbmle",
"plyr","numDeriv","Hmisc",
"plotMCMC","gridExtra","R2admb",
"broom.mixed","dotwhisker")
install.packages(pkgs_CRAN)
install.packages("R2admb")
install.packages("glmmADMB",
repos=c("http://glmmadmb.r-forge.r-project.org/repos",
getOption("repos")),
type="source")
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library("tidyverse"))
suppressMessages(library("lme4"))
suppressMessages(library("afex"))
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library("tidyverse"))
suppressMessages(library("lme4"))
suppressMessages(library("afex"))
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library("tidyverse"))
suppressMessages(library("afex"))
suppressMessages(library("lme4"))
?mixed
raw_data               <- read.csv(file="all_data.csv",head=TRUE)
data_df                <- raw_data
data_df$subid          <- factor(data_df$subid)
data_df$appearance     <- factor(data_df$appearance)
data_df$pro            <- factor(data_df$pro)
sub_n                  <- length(levels(data_df$subid))
sub_name               <- as.character(levels(data_df$subid))
#for RT data
#1. remove 2301~2307
data.rt        <- data_df %>% filter(subid != 2301 & subid != 2302 & subid != 2303 & subid != 2304 & subid != 2305 & subid != 2306 & subid != 2307)
data.rt        <- data.rt %>% filter(ACC != 0) #excluding wrong responses
data.rt        <- data.rt %>% filter(RT > 0.1) # excluding fast responses, i.e., less than 0.1 s
hist(data.rt$RT)
#for ACC data
data.acc        <- data_df %>% filter(RT != 0) #excluding non-response trials
hist(data.acc$ACC)
#1. how many subjects remained
data.rt %>% group_by(subid) %>% summarize() %>% nrow()
data.acc %>% group_by(subid) %>% summarize() %>% nrow()
#2. how many trials left for each subjects
tRT <- data.rt %>% group_by(subid) %>% summarize(trialn=length(subid))
min(tRT$trialn)# check if any subjects have less than like 100 trials
tACC <- data.acc %>% group_by(subid) %>% summarize(trialn=length(subid))
min(tACC$trialn)# check if any subjects have less than like 100 trials
#3. check the levels of the factors
levels(data_df$appearance)
levels(data_df$pro)
#m1 just to check if the model could convergent.
#1. RT, using the LMM here, since our RT data distributions looks quite "normal"
m1.rt <- mixed(RT ~ 1+appearance * pro * trial + (1 + pro * trial | subid), data.rt,method='S',
control = lmerControl(optCtrl = list(maxfun = 1e6)))
#2. using the GLMM with the family option.
m1.acc <- mixed(ACC ~ 1+appearance * pro * trial + (1 + pro * trial | subid), data.acc, method='PB',
control = lmerControl(optCtrl = list(maxfun = 1e6)),family="binomial")
m1.acc <- mixed(ACC ~ 1+appearance * pro * trial + (1 + pro * trial | subid), data.acc, method='LRT', # PB is too slow
control = glmerControl(optCtrl = list(maxfun = 1e6)),family="binomial")
?glmer
#m1 just to check if the model could be convergent, no significant test here
#1. RT, using the LMM here, since our RT data distributions looks quite "normal"
m1.rt <- lmer(RT ~ 1 + appearance * pro * trial +
(1 + pro * trial | subid),
data = data.rt,control = lmerControl(optCtrl = list(maxfun = 1e6)))
m1.acc <- glmer(ACC ~ 1+appearance * pro * trial + (1 + pro * trial | subid), data=data.acc, # PB is too slow
control = glmerControl(optCtrl = list(maxfun = 1e6)),family="binomial")
m1.acc <- glmer(ACC ~ 1+appearance * pro * trial + (1 + pro * trial | subid), data=data.acc, family="binomial")
all_fit(m1.rt)
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries
suppressMessages(library("tidyverse"))
suppressMessages(library("afex"))
suppressMessages(library("lme4"))
suppressMessages(library("emmeans"))  # emmeans is needed for follow-up tests
suppressMessages(library("multcomp")) # for advanced control for multiple testing/Type 1 errors.
suppressMessages(library("ggeffects")) # for plotting (G)LMM results
suppressMessages(library('car')) # setting labeled contrasts
select <- dplyr::select # to avoid clashes with the MASS package
?ggpredict
package_info(10)
usethis::edit_r_profile(scope='user')
package_info(10)
x=package_info(10)
View(package_info)
usethis::edit_r_profile(scope='user')
View(package_info)
usethis::edit_r_profile(scope='user')
setwd("E:/Em_computer/Feng/presence_effect/learning/learning_allstuff/behav_data/comp_modeling")
rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("func01_prepro.R") #preparing the data for the stan:                         change for each project
source("func02_get_ini.R") #get starting point using VB for simulation:             no changes needed
source("func03_get_pars.R") #setting parameters of interest for stan:               change for each project
source("func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("func06_modeldata.R") #wrap all the model-related data to a list:            no change needed
source("func07_plot_hBayesDM.R") #plotting the model:                               change for each project and the best model
raw_data                     <- fread(file="all_data.csv") #
data_df                      <- raw_data
class(data_df)
View(data_df)
names(data_df)
View(data_df)
NaN!=0
rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM, so load before it.
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("func01_prepro.R") #preparing the data for the stan:                         change for each project
source("func02_get_ini.R") #get starting point using VB for simulation:             no changes needed
source("func03_get_pars.R") #setting parameters of interest for stan:               change for each project
source("func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("func06_modeldata.R") #wrap all the model-related data to a list:            no change needed
source("func07_plot_hBayesDM.R") #plotting the model:                               change for each project and the best model
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice')]
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM, so load before it.
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("func01_prepro.R") #preparing the data for the stan:                         change for each project
source("func02_get_ini.R") #get starting point using VB for simulation:             no changes needed
source("func03_get_pars.R") #setting parameters of interest for stan:               change for each project
source("func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("func06_modeldata.R") #wrap all the model-related data to a list:            no change needed
source("func07_plot_hBayesDM.R") #plotting the model:                               change for each project and the best model
raw_data                     <- fread(file="all_data.csv") #load as data.table: https://digitaschools.com/read-csv-in-r-importing-data/
data_df                      <- raw_data
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice')]
#2. removing NaNs
data_df <- data_df %>% filter(!is.nan(choice)) #excluding non-response trials
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM, so load before it.
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("func01_prepro.R") #preparing the data for the stan:                         change for each project
source("func02_get_ini.R") #get starting point using VB for simulation:             no changes needed
source("func03_get_pars.R") #setting parameters of interest for stan:               change for each project
source("func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("func06_modeldata.R") #wrap all the model-related data to a list:            no change needed
source("func07_plot_hBayesDM.R") #plotting the model:                               change for each project and the best model
raw_data                     <- fread(file="all_data.csv") #load as data.table: https://digitaschools.com/read-csv-in-r-importing-data/
data_df                      <- raw_data
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice')]
#2. removing NaNs
data_df <- data_df %>% filter(!is.nan(choice)) #excluding non-response trials
View(data_df)
unique(data_df$subid)
unique(data_df$cond)
length(unique(data_df$cond))
length(unique(data_df$subid))
setwd("E:/Em_computer/Feng/ITE_fMRI/behav_data/hBayesDM/hBayesDM-master/R/R")
setwd("E:/Em_computer/Feng/ITE_fMRI/behav_data/hBayesDM/hBayesDM-master/commons/stan_files")
setwd("E:/Em_computer/Feng/presence_effect/learning/learning_allstuff/behav_data/comp_modeling/supp_funcs")
?sign
sign(c(1,0))
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM, so load before it.
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting
suppressMessages(library('loo'))   # for calculating looic and waic
#suppressMessages(library('parallel'))
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame. already in the hBayesDM, so load before it.
suppressMessages(library('hBayesDM')) #we cannot use hBayesDM_model.R with the package
suppressMessages(library("reshape2"))
#source("hBayesDM_model.R") #directly call the function
#The following functions are adapted from the hBayesDM package.
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func02_get_ini.R") #get starting point using VB for simulation:             no changes needed
source("./supp_funcs/func03_get_pars.R") #setting parameters of interest for stan:               change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/func06_modeldata.R") #wrap all the model-related data to a list:            no change needed
source("./supp_funcs/func07_plot_hBayesDM.R") #plotting the model:                               change for each project and the best model
raw_data                     <- fread(file="all_data.csv") #load as data.table: https://digitaschools.com/read-csv-in-r-importing-data/
data_df                      <- raw_data
# 1. Target variable:      choice (1 or 2). (we want our models to accurately predict participants' choice on each trial as much as possible)
# 2. Predictor variable:   feedback (0 or 1) of previous trial. According to the RL, we expect participants learn the stimulus-response association based on feedback.
# 3. supporting variables: subid (2301~2347), block (1~5), trial_perC (1~25), cond (1~6).
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice')]
#2. removing NaNs
data_df <- data_df %>% filter(!is.nan(choice)) #excluding non-response trials
View(data_df)
names(data_df)
colnames_data_df <- colnames(data_df)
subjs    <- NULL   # List of unique subjects (1D)
n_subj   <- NULL   # Total number of subjects (0D)
b_subjs  <- NULL   # number of blocks for each sub
b_max    <- NULL   # maximum number of blocks across subjects
t_subjs  <- NULL   # Number of trials per block per subject (2D or 1D)
t_max    <- NULL   # Maximum number of trials across all blocks & subjects (0D)
.N       <- NULL
subjid   <- NULL
DT_trials <- data_df[, .N, by = c("subid", "block")]
View(DT_trials)
DT_trials2 <- data_df %>% group_by(subid,block) %>% summarise(n())
View(DT_trials2)
DT_trials2 <- data_df %>% group_by(subid,block) %>% summarise(N=n())
unique(DT_trials$N - DT_trials2$N)
DT_blocks <- DT_trials %>% group_by(subid) %>% summarise(N=n()) # get the number of blocks for each sub
DT_blocks2 <-  DT_trials[, .N, by = "subid"]
View(DT_blocks)
View(DT_blocks2)
View(DT_blocks)
View(DT_blocks2)
colnames_data_df <- colnames(data_df)
subjs    <- NULL   # List of unique subjects (1D)
n_subj   <- NULL   # Total number of subjects (0D)
b_subjs  <- NULL   # number of blocks for each sub
b_max    <- NULL   # maximum number of blocks across subjects
t_subjs  <- NULL   # Number of trials per block per subject (2D or 1D)
t_max    <- NULL   # Maximum number of trials across all blocks & subjects (0D)
.N       <- NULL
subjid   <- NULL
DT_trials <- data_df %>% group_by(subid,block) %>% summarise(N=n()) #get the number of trials for each sub and each block
DT_blocks <- DT_trials %>% group_by(subid) %>% summarise(N=n()) # get the number of blocks for each sub
subjs     <- DT_blocks$subjid   # sub IDs
n_subj    <- length(subjs)      # no. of subs
b_subjs   <- DT_blocks$N        # block numbers
b_max     <- max(b_subjs)       # maximal number of blocks
t_subjs   <- array(0, c(n_subj, b_max)) # trial number for each sub and block
for (i in 1:n_subj) {
subj <- subjs[i]  # current sub
b <- b_subjs[i]   # no. of blocks for the current sub.
t_subjs[i, 1:b] <- DT_trials[subjid == subj]$N # no. of trials for all blocks of the current sub
}
DT_trials <- data_df %>% group_by(subid,block) %>% summarise(N=n()) #get the number of trials for each sub and each block
DT_blocks <- DT_trials %>% group_by(subid) %>% summarise(N=n()) # get the number of blocks for each sub
subjs     <- DT_blocks$subid    # sub IDs
n_subj    <- length(subjs)      # no. of subs
b_subjs   <- DT_blocks$N        # block numbers
b_max     <- max(b_subjs)       # maximal number of blocks
t_subjs   <- array(0, c(n_subj, b_max)) # trial number for each sub and block
for (i in 1:n_subj) {
subj <- subjs[i]  # current sub
b <- b_subjs[i]   # no. of blocks for the current sub.
t_subjs[i, 1:b] <- DT_trials[subid == subj]$N # no. of trials for all blocks of the current sub
}
View(DT_trials)
class(DT_trials)
DT_trials <- data_df[, .N, by = c("subid", "block")] #get the number of trials for each sub and each block, data.table
DT_blocks <- DT_trials[, .N, by = "subid"] # get the number of blocks for each sub, data.table
subjs     <- DT_blocks$subid    # sub IDs
n_subj    <- length(subjs)      # no. of subs
b_subjs   <- DT_blocks$N        # block numbers
b_max     <- max(b_subjs)       # maximal number of blocks
t_subjs   <- array(0, c(n_subj, b_max)) # trial number for each sub and block
for (i in 1:n_subj) {
subj <- subjs[i]  # current sub
b <- b_subjs[i]   # no. of blocks for the current sub.
t_subjs[i, 1:b] <- DT_trials[subid == subj]$N # no. of trials for all blocks of the current sub
}
class(dta_df)
class(data_df)
t_max     <- max(t_subjs)
x=c(-0.4,-0.6,0,0.4,0.6)
sign(x)
View(data_df)
?options
