m_names      <- m_names[1:count]
allIndPars <- cbind(subjs, allIndPars,m_allIndPars)
colnames(allIndPars) <- c("subjid", which_indPars,m_names)
} else {
allIndPars <- cbind(subjs, allIndPars)
colnames(allIndPars) <- c("subjid", which_indPars)
}
View(allIndPars)
View(allIndPars)
write.csv(allIndPars,file='IndPars_fitm7c2_alone.csv',row.names = FALSE)
printFit(fit_m7c2,ic="both")
print(fit_m7c2, pars = c("mu_etar","mu_etap","mu_kapa","mu_tau","mu_etack","mu_tauck","mu_fp",'sigma')) #all are group-level parameters
#plot group parameters
stan_dens(fit_m7c2, pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")), separate_chains = T) #should overlap to each other
#plot individual parameters
stan_plot(fit_m7c2, pars = "etar", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "etap", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "kapa", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "tau", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "etack", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "tauck", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "fp", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
#################################################################model diagnostics#########################################################################
#various plotting with bayesplot: see also https://dastatis.github.io/pdf/StanAdvent2018/bayesplot.html
#see also: "RStan: the R interface to Stan"
#see also: https://betanalpha.github.io/assets/case_studies/rstan_workflow.html
###1. Convergence and divergence
#1.1. overlaps between different chains
traceplot(fit_m7c2, pars = c("mu_etar","mu_etap","mu_kapa","mu_tau","mu_etack","mu_tauck","mu_fp",'sigma')) #all are group-level parameters # should be stationary and overylap to each other
mcmc_rank_hist(fit_m7c2, pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")), ref_line = TRUE) # should be uniformly distributed
#1.2. Rhat, must be below 1.01 to make sure that parameter estimates could be trusted (Baribault & Collins, 2022)
#get the rhat values for all (including both group and individual) parameters
rhats <- mcmc_rhat_data(rhat(fit_m7c2)) # a tibble format
stan_rhat(fit_m7c2)
#stan_rhat(fit_m7c2)$data
mcmc_rhat(rhat(fit_m7c2))
#1.3.energy diagnostic plot, E and deltaE should overlap each other.
mcmc_nuts_energy(nuts_params(fit_m7c2))
###2. Sampling efficiency
#2.1. for n_eff ratio, if it is less than 0.1, indicating high auto-correlation, model fitting fails
#get the n_eff ratio values for all (including both group and individual) parameters
neff_ratio <- mcmc_neff_data(neff_ratio(fit_m7c2)) # a tibble format
stan_ess(fit_m7c2)
mcmc_neff(neff_ratio(fit_m7c2))
#2.2. auto correlations, should decrease with lag (larger correlation with small lag, but smaller correlation with large lag)
mcmc_acf(as.array(fit_m7c2), pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")),inc_warmup = F)
#2.3. for total sample size, should be 4000.
length(extract(fit_m7c2, pars = "lp__")[[1]])
#3. for divergent transitions, n_treedepth, accept_stat (i.e., adapt_delta parameter), stepsize, and energy
summary(do.call(rbind,args = get_sampler_params(fit_m7c2,inc_warmup = F)),digits=2) # across all chains
lapply(get_sampler_params(fit_m7c2,inc_warmup = F),summary,digits=2) # for each chain
check_hmc_diagnostics(fit_m7c2) # explicit checking of above parameters,including warmup transitions
#4. NUTS diagnose
stan_diag(fit_m7c2)
setwd("D:/projects/learning_allstuff/behav_data_new/comp_modeling/Final_v1/Audience")
load("D:/projects/learning_allstuff/behav_data_new/comp_modeling/Final_v1/Audience/fit_m7c2.RData")
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
#The following functions are adapted from the hBayesDM package (Ahn et al., 2017).
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/estimate_mode.R") #estimate the mode (众数) of the posterior distribution:  no change needed
options(max.print = 99999) # for ploting all results of fitted model
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
#The following functions are adapted from the hBayesDM package (Ahn et al., 2017).
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/estimate_mode.R") #estimate the mode (众数) of the posterior distribution:  no change needed
options(max.print = 99999) # for ploting all results of fitted model
raw_data                     <- fread(file="all_data.csv") #load as data.table: https://digitaschools.com/read-csv-in-r-importing-data/
data_df                      <- raw_data
# 1. Target variable:      choice (1 or 2). (we want our models to accurately predict participants' choice on each trial as much as possible)
# 2. Predictor variable:   (1) feedback (0 or 1) of previous trial. According to the RL, we expect participants learn the stimulus-response association based on feedback; (2) choice history/decision inertia: how many times the current choice has been previously chosen; (3) working memory: delay between stimulus repetitions.
# 3. supporting variables: subid (2301~2347), block (1~5), trial_perC (1~25), cond (1~6), delay (0~45)
#0. left only audience participants
data_df <- data_df %>% filter(appearance==1) #including audience participants
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice','delay','ACC')]
#2. removing NaNs
data_df <- data_df %>% filter(!is.nan(choice)) #excluding non-response trials, we can only exclude trials with this.
#data_df <- data_df %>% filter(!is.nan(delay)) #excluding first trial of each pic in each block: we should not do this.
#3. convert feedback to -1 (wrong) and 1 (correct)
data_df$feedback <- ifelse(data_df$feedback == 0, -1, 1) # change the initial ev in the stan files accordingly!!!
#4. convert trial_perC, ignoring the trial number of non-responded trials.
data_df <- data_df %>%
group_by(subid,block,cond) %>%
mutate(trial_perC2 = 1:n()) #ignoring the missed trials
#5. convert condition (1~6) to probability (1~3)
data_df <- data_df %>%
mutate(probab = case_when( cond %in% c(1,2) ~ 1,
cond %in% c(3,4) ~ 2,
cond %in% c(5,6) ~ 3)) # probability
#data_for_cm_all <- data_df[,c('subid','block','cond','feedback','choice','trial_perC2','probab','delay')]
#write.csv(data_for_cm_all,file='data_for_cm_all.csv',row.names = FALSE)
data_df <- as.data.table(data_df)
class(data_df)
colnames_data_df <- colnames(data_df)
subjs    <- NULL   # List of unique subjects (1D)
n_subj   <- NULL   # Total number of subjects (0D)
b_subjs  <- NULL   # number of blocks for each sub
b_max    <- NULL   # maximum number of blocks across subjects
t_subjs  <- NULL   # Number of trials per block per subject (2D or 1D)
t_max    <- NULL   # Maximum number of trials across all blocks & subjects (0D)
.N       <- NULL
subjid   <- NULL
DT_trials <- data_df[, .N, by = c("subid", "block")] #get the number of trials for each sub and each block, data.table
DT_blocks <- DT_trials[, .N, by = "subid"] # get the number of blocks for each sub, data.table
subjs     <- DT_blocks$subid    # sub IDs
n_subj    <- length(subjs)      # no. of subs
b_subjs   <- DT_blocks$N        # block numbers
b_max     <- max(b_subjs)       # maximal number of blocks
t_subjs   <- array(0, c(n_subj, b_max)) # trial number for each sub and block
for (i in 1:n_subj) {
subj <- subjs[i]  # current sub
b <- b_subjs[i]   # no. of blocks for the current sub.
t_subjs[i, 1:b] <- DT_trials[subid == subj]$N # no. of trials for all blocks of the current sub
}
t_max     <- max(t_subjs) # maximal no. of trials across all blocks and subs.
gen_file <- 1 #whether or not generate a data file, only generating for main analysis
general_info        <- list(subjs, n_subj, b_subjs, b_max, t_subjs, t_max,gen_file)
names(general_info) <- c("subjs", "n_subj", "b_subjs", "b_max", "t_subjs", "t_max","gen_file")
data_list <- prepro_func(data_df,general_info)  # get the data ready for stan
printFit(fit_m7c2,ic="both")
print(fit_m7c2, pars = c("mu_etar","mu_etap","mu_kapa","mu_tau","mu_etack","mu_tauck","mu_fp",'sigma')) #all are group-level parameters
#plot group parameters
stan_dens(fit_m7c2, pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")), separate_chains = T) #should overlap to each other
#plot individual parameters
stan_plot(fit_m7c2, pars = "etar", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "etap", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "kapa", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "tau", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "etack", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "tauck", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
stan_plot(fit_m7c2, pars = "fp", ci_level = 0.95, outer_level = 1, show_density = T, point_est = "mean")
#################################################################model diagnostics#########################################################################
#various plotting with bayesplot: see also https://dastatis.github.io/pdf/StanAdvent2018/bayesplot.html
#see also: "RStan: the R interface to Stan"
#see also: https://betanalpha.github.io/assets/case_studies/rstan_workflow.html
###1. Convergence and divergence
#1.1. overlaps between different chains
traceplot(fit_m7c2, pars = c("mu_etar","mu_etap","mu_kapa","mu_tau","mu_etack","mu_tauck","mu_fp",'sigma')) #all are group-level parameters # should be stationary and overylap to each other
mcmc_rank_hist(fit_m7c2, pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")), ref_line = TRUE) # should be uniformly distributed
#1.2. Rhat, must be below 1.01 to make sure that parameter estimates could be trusted (Baribault & Collins, 2022)
#get the rhat values for all (including both group and individual) parameters
rhats <- mcmc_rhat_data(rhat(fit_m7c2)) # a tibble format
stan_rhat(fit_m7c2)
#stan_rhat(fit_m7c2)$data
mcmc_rhat(rhat(fit_m7c2))
#1.3.energy diagnostic plot, E and deltaE should overlap each other.
mcmc_nuts_energy(nuts_params(fit_m7c2))
###2. Sampling efficiency
#2.1. for n_eff ratio, if it is less than 0.1, indicating high auto-correlation, model fitting fails
#get the n_eff ratio values for all (including both group and individual) parameters
neff_ratio <- mcmc_neff_data(neff_ratio(fit_m7c2)) # a tibble format
stan_ess(fit_m7c2)
mcmc_neff(neff_ratio(fit_m7c2))
#2.2. auto correlations, should decrease with lag (larger correlation with small lag, but smaller correlation with large lag)
mcmc_acf(as.array(fit_m7c2), pars = paste0(c("mu_etar","mu_etap","mu_kapa[1]","mu_kapa[2]","mu_kapa[3]","mu_tau","mu_etack","mu_tauck","mu_fp")),inc_warmup = F)
#2.3. for total sample size, should be 4000.
length(extract(fit_m7c2, pars = "lp__")[[1]])
#3. for divergent transitions, n_treedepth, accept_stat (i.e., adapt_delta parameter), stepsize, and energy
summary(do.call(rbind,args = get_sampler_params(fit_m7c2,inc_warmup = F)),digits=2) # across all chains
lapply(get_sampler_params(fit_m7c2,inc_warmup = F),summary,digits=2) # for each chain
check_hmc_diagnostics(fit_m7c2) # explicit checking of above parameters,including warmup transitions
#4. NUTS diagnose
stan_diag(fit_m7c2)
# #5. correlations of posterior samples of different parameters
# #color_scheme_set("darkgray")
# mcmc_pairs(
#   as.array(fit_m7c2),
#   pars = paste0(c("mu_etar","mu_etap","mu_kapa","mu_tau","mu_etack","mu_tauck","mu_fp")),
#   np = nuts_params(fit_m7c2))
###########################################################################individual paramters#######################################################################
# Extract from the Stan fit object
parVals <- rstan::extract(fit_m7c2, permuted = TRUE)
# Define measurement of individual parameters
indPars <- "mean" #extracting mean of parameters
measure_indPars <- switch(indPars, mean = mean, median = median, mode = estimate_mode)
which_indPars <- c("etar","etap","tau","etack","tauck","fp")
multp_which_indPars <- 'kapa'
# Measure all individual parameters (per subject)
allIndPars <- as.data.frame(array(NA, c(n_subj, length(which_indPars))))
m_allIndPars <- as.data.frame(array(NA, c(n_subj, 50)))
m_names  <- rep(NULL,50)
for (i in 1:n_subj) {
allIndPars[i, ] <- mapply(function(x) measure_indPars(parVals[[x]][, i]), which_indPars)
if (length(multp_which_indPars)>0){  # for parameters in the matrix form
count <-0
for (nm in 1: length(multp_which_indPars)){
for (ds in 1:dim(parVals[[multp_which_indPars[nm]]])[3]){
count <- count + 1
m_allIndPars[i, count] <- sapply(list(parVals[[multp_which_indPars[nm]]][, i,ds]),function(x) measure_indPars(x))
m_names[count] <- paste0(multp_which_indPars[nm],ds)
}
}
}
}
if (length(multp_which_indPars)>0){
m_allIndPars <- m_allIndPars[,1:count]
m_allIndPars <- as.data.frame(m_allIndPars)
m_names      <- m_names[1:count]
allIndPars <- cbind(subjs, allIndPars,m_allIndPars)
colnames(allIndPars) <- c("subjid", which_indPars,m_names)
} else {
allIndPars <- cbind(subjs, allIndPars)
colnames(allIndPars) <- c("subjid", which_indPars)
}
write.csv(allIndPars,file='IndPars_fitm7c2_audience.csv',row.names = FALSE)
View(allIndPars)
setwd("D:/projects/learning_allstuff/behav_data_new/comp_modeling/Final_v1")
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
suppressMessages(library("ggplot2")) # for plotting.
suppressMessages(library("ggsci")) # for setting scientific jouranl color palettes
suppressMessages(library("gridExtra")) # for arranging the position of figures
suppressMessages(library("ggpubr")) # using the ggexport
source("./HDIofMCMC.R") #compute the 95% HDI: change for each project
source("./plotHDI.R") #plot the distribution and the 95% HDI: no chnage needed
#plot function, this one handles continuous variables
cplot <- function(d,xlimits,xbreaks,ylimits,ybreaks,xlabs,ylabs){
fig <- ggplot(d, aes(trial_perC2, means)) +
#geom_point(data=data.acc, aes(trial_perC.cwc, ACC, color = appearance), alpha = 0.5) + #not necessary
geom_line(aes(color = group)) +  # in the mydf, 'group' refer to real or simulated
geom_ribbon(aes(ymin = conf.low, ymax = conf.high,fill=group), alpha=0.1)+
scale_x_continuous(limits = xlimits,breaks = xbreaks,expand = c(0, 0.5))+ # no expand, i.e., really from lower limits and really ends with higher limits
scale_y_continuous(limits = ylimits,breaks = ybreaks,expand = c(0, 0.05))+ #https://stackoverflow.com/questions/13701347/force-the-origin-to-start-at-0
labs(x = xlabs, y = ylabs)+
#scale_color_lancet()+ #https://cran.r-project.org/web/packages/ggsci/vignettes/ggsci.html
#scale_fill_lancet()+
scale_colour_manual(values=c('#4DBBD6','#039F87'))+
scale_fill_manual(values=c('#4DBBD6','#039F87'))+
theme_classic()+
theme(legend.position="top")+
theme(axis.ticks.length = unit(0.1, "cm"))+
theme(axis.text.x = element_text(size=20,colour='black',family =windowsFont("RMN")),axis.text.y =         element_text(size=20,colour='black',family=windowsFont("RMN")),axis.title= element_text(size=24,colour='black',family=windowsFont("RMN")))
}
load('./Audience/fit_m7c2.RData')
parVals_aud <- rstan::extract(fit_m7c2, permuted = TRUE)
#fit_aud <- fit_m7c2
rm(fit_m7c2)
load('./Alone/fit_m7c2.RData')
parVals_ane <- rstan::extract(fit_m7c2, permuted = TRUE)
#fit_ane <- fit_m7c2
rm(fit_m7c2)
#1. mu_tau
diff_tau_dis <- parVals_aud$mu_tau - parVals_ane$mu_tau #get the differences of mu_tau between two groups
HDIofMCMC(diff_tau_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_tau.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_tau_dis) #plot it.
dev.off()
#2. mu_tauck
diff_tauck_dis <- parVals_aud$mu_tauck - parVals_ane$mu_tauck #get the differences of mu_tauck between two groups
HDIofMCMC(diff_tauck_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_tauck.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_tauck_dis) #plot it.
dev.off()
#3. mu_fp
diff_fp_dis <- parVals_aud$mu_fp - parVals_ane$mu_fp #get the differences of mu_fp between two groups
HDIofMCMC(diff_fp_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_fp.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_fp_dis) #plot it.
dev.off()
#4.1 mu_etar
diff_etar_dis <- parVals_aud$mu_etar - parVals_ane$mu_etar  #get the differences of mu_eta between two groups
HDIofMCMC(diff_etar_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_etar.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_etar_dis) #plot it.
dev.off()
#4.2 mu_etap
diff_etap_dis <- parVals_aud$mu_etap - parVals_ane$mu_etap  #get the differences of mu_eta between two groups
HDIofMCMC(diff_etap_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_etap.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_etap_dis) #plot it.
dev.off()
#4.3 mu_etar - mu_etap
diff_eta_dis_aud <- parVals_aud$mu_etar - parVals_aud$mu_etap #get the differences of mu_eta between conditions
HDIofMCMC(diff_eta_dis_aud) #calculate the 95% HDI of the differences
png("Figure_Audience_eta_RvsP.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_eta_dis_aud) #plot it.
dev.off()
diff_eta_dis_ane <- parVals_ane$mu_etar - parVals_ane$mu_etap #get the differences of mu_eta between conditions
HDIofMCMC(diff_eta_dis_ane) #calculate the 95% HDI of the differences
png("Figure_Alone_eta_RvsP.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_eta_dis_ane) #plot it.
dev.off()
diff_eta_dis <- (parVals_aud$mu_etar - parVals_aud$mu_etap) - (parVals_ane$mu_etar - parVals_ane$mu_etap) #get the differences of mu_eta between two groups
HDIofMCMC(diff_eta_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_eta_RvsP.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_eta_dis) #plot it.
dev.off()
#5. mu_kapa[1] - mu_kapa[3] i.e., 100% vs. 50%
diff_kapa13_dis_aud <- parVals_aud$mu_kapa[,1] - parVals_aud$mu_kapa[,3] #get the differences of mu_kapa between 100% and 50%
HDIofMCMC(diff_kapa13_dis_aud) #calculate the 95% HDI of the differences
png("Figure_Audience_kapa_1vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa13_dis_aud) #plot it.
dev.off()
diff_kapa13_dis_ane <- parVals_ane$mu_kapa[,1] - parVals_ane$mu_kapa[,3] #get the differences of mu_kapa between 100% and 50%
HDIofMCMC(diff_kapa13_dis_ane) #calculate the 95% HDI of the differences
png("Figure_Alone_kapa_1vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa13_dis_ane) #plot it.
dev.off()
diff_kapa13_dis <- (parVals_aud$mu_kapa[,1] - parVals_aud$mu_kapa[,3]) - (parVals_ane$mu_kapa[,1] - parVals_ane$mu_kapa[,3]) #get the differences of mu_kapa between 100% and 50% and between two groups
HDIofMCMC(diff_kapa13_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_kapa_1vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa13_dis) #plot it.
dev.off()
#6. mu_kapa[2] - mu_kapa[3] i.e., 80% vs. 50%
diff_kapa23_dis_aud <- parVals_aud$mu_kapa[,2] - parVals_aud$mu_kapa[,3] #get the differences of mu_kapa between 80% and 50%
HDIofMCMC(diff_kapa23_dis_aud) #calculate the 95% HDI of the differences
png("Figure_Audience_kapa_2vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa23_dis_aud) #plot it.
dev.off()
diff_kapa23_dis_ane <- parVals_ane$mu_kapa[,2] - parVals_ane$mu_kapa[,3] #get the differences of mu_kapa between 100% and 50%
HDIofMCMC(diff_kapa23_dis_ane) #calculate the 95% HDI of the differences
png("Figure_Alone_kapa_2vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa23_dis_ane) #plot it.
dev.off()
diff_kapa23_dis <- (parVals_aud$mu_kapa[,2] - parVals_aud$mu_kapa[,3]) - (parVals_ane$mu_kapa[,2] - parVals_ane$mu_kapa[,3]) #get the differences of mu_kapa between 100% and 50% and between two groups
HDIofMCMC(diff_kapa23_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_kapa_2vs3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa23_dis) #plot it.
dev.off()
#12.1 mu_kapa[1]
diff_kapa1_dis <- parVals_aud$mu_kapa[,1] - parVals_ane$mu_kapa[,1] #get the differences of mu_kapa1 between two groups
HDIofMCMC(diff_kapa1_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_kapa1.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa1_dis) #plot it.
dev.off()
#12.2 mu_kapa[2]
diff_kapa2_dis <- parVals_aud$mu_kapa[,2] - parVals_ane$mu_kapa[,2] #get the differences of mu_kapa2 between two groups
HDIofMCMC(diff_kapa2_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_kapa2.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa2_dis) #plot it.
dev.off()
#12.3 mu_kapa[3]
diff_kapa3_dis <- parVals_aud$mu_kapa[,3] - parVals_ane$mu_kapa[,3] #get the differences of mu_kapa3 between two groups
HDIofMCMC(diff_kapa3_dis) #calculate the 95% HDI of the differences
png("Figure_AudiencevsAlone_kapa3.png", width = 6, height = 6, units = 'in', res = 300)
plotHDI(diff_kapa3_dis) #plot it.
dev.off()
setwd("D:/projects/learning_allstuff/behav_data_new/comp_modeling/Final_v1/Alone")
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
#The following functions are adapted from the hBayesDM package (Ahn et al., 2017).
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/estimate_mode.R") #estimate the mode (众数) of the posterior distribution:  no change needed
options(max.print = 99999) # for ploting all results of fitted model
load('fit_m7c2.RData')
parVals <- rstan::extract(fit_m7c2, permuted = TRUE)
tests <- parVals$kapa[,1]
tests <- parVals$kapa
kapa1    <- parVals[['kapa'[1]]] # a 60000*23 matrix
kapa1    <- parVals['kapa'][,,1] # a 60000*23 matrix
unts <- unlist(tests)
kapa1    <- parVals[['kapa']][,,1] # a 60000*23 matrix
etar     <- parVals$etar                 # a 60000*23 matrix
etap     <- parVals$etap                # a 60000*23 matrix
tau      <- parVals$tau                # a 60000*23 matrix
etack    <- parVals$etack             # a 60000*23 matrix
tauck    <- parVals$tauck            # a 60000*23 matrix
fp       <- parVals$fp              # a 60000*23 matrix
kapa1    <- parVals[['kapa']][,,1] # a 60000*23 matrix
kapa2    <- parVals[['kapa']][,,2] # a 60000*23 matrix
kapa3    <- parVals[['kapa']][,,3] # a 60000*23 matrix
writeMat('m7c2_subwise_para_alone.mat',etar=etar,etap=etap,tau=tau,etack=etack,tauck=tauck,fp=fp,kapa1=kapa1,kapa2=kapa2,kapa3=kapa3)
setwd("D:/projects/learning_allstuff/behav_data_new/comp_modeling/Final_v1/Audience")
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
#The following functions are adapted from the hBayesDM package (Ahn et al., 2017).
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/estimate_mode.R") #estimate the mode (众数) of the posterior distribution:  no change needed
options(max.print = 99999) # for ploting all results of fitted model
#rm(list=ls())
require("knitr")
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
#load libraries and functions
suppressMessages(library("tidyverse")) # to organize data
suppressMessages(library('rstan')) # for model fiting, using the sampling function
rstan_options(auto_write = TRUE) #which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it): https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
suppressMessages(library('loo'))   # for calculating looic and waic
suppressMessages(library("data.table")) # to read data as data.table rather than data.frame.
suppressMessages(library("bayesplot")) # to plot various figures for model checking
suppressMessages(library("R.matlab")) # to save out .mat files
suppressMessages(library("hypr")) # transfer hypothesis matrix to contrast matrix.
#The following functions are adapted from the hBayesDM package (Ahn et al., 2017).
source("./supp_funcs/func01_prepro.R") #preparing the data for the stan:                         change for each project
source("./supp_funcs/func04_extract_ic.R") #extract looic and waic of the model:                 no chnage needed
source("./supp_funcs/func05_printfit.R") #print looic and waic of the model and their weights:   no change needed
source("./supp_funcs/estimate_mode.R") #estimate the mode (众数) of the posterior distribution:  no change needed
options(max.print = 99999) # for ploting all results of fitted model
raw_data                     <- fread(file="all_data.csv") #load as data.table: https://digitaschools.com/read-csv-in-r-importing-data/
data_df                      <- raw_data
# 1. Target variable:      choice (1 or 2). (we want our models to accurately predict participants' choice on each trial as much as possible)
# 2. Predictor variable:   (1) feedback (0 or 1) of previous trial. According to the RL, we expect participants learn the stimulus-response association based on feedback; (2) choice history/decision inertia: how many times the current choice has been previously chosen; (3) working memory: delay between stimulus repetitions.
# 3. supporting variables: subid (2301~2347), block (1~5), trial_perC (1~25), cond (1~6), delay (0~45)
#0. left only audience participants
data_df <- data_df %>% filter(appearance==1) #including audience participants
#1. only left the necessary variables
data_df <- data_df[,c('subid','block','trial_perC','cond','feedback','choice','delay','ACC')]
#2. removing NaNs
data_df <- data_df %>% filter(!is.nan(choice)) #excluding non-response trials, we can only exclude trials with this.
#data_df <- data_df %>% filter(!is.nan(delay)) #excluding first trial of each pic in each block: we should not do this.
#3. convert feedback to -1 (wrong) and 1 (correct)
data_df$feedback <- ifelse(data_df$feedback == 0, -1, 1) # change the initial ev in the stan files accordingly!!!
#4. convert trial_perC, ignoring the trial number of non-responded trials.
data_df <- data_df %>%
group_by(subid,block,cond) %>%
mutate(trial_perC2 = 1:n()) #ignoring the missed trials
#5. convert condition (1~6) to probability (1~3)
data_df <- data_df %>%
mutate(probab = case_when( cond %in% c(1,2) ~ 1,
cond %in% c(3,4) ~ 2,
cond %in% c(5,6) ~ 3)) # probability
#data_for_cm_all <- data_df[,c('subid','block','cond','feedback','choice','trial_perC2','probab','delay')]
#write.csv(data_for_cm_all,file='data_for_cm_all.csv',row.names = FALSE)
data_df <- as.data.table(data_df)
class(data_df)
colnames_data_df <- colnames(data_df)
subjs    <- NULL   # List of unique subjects (1D)
n_subj   <- NULL   # Total number of subjects (0D)
b_subjs  <- NULL   # number of blocks for each sub
b_max    <- NULL   # maximum number of blocks across subjects
t_subjs  <- NULL   # Number of trials per block per subject (2D or 1D)
t_max    <- NULL   # Maximum number of trials across all blocks & subjects (0D)
.N       <- NULL
subjid   <- NULL
DT_trials <- data_df[, .N, by = c("subid", "block")] #get the number of trials for each sub and each block, data.table
DT_blocks <- DT_trials[, .N, by = "subid"] # get the number of blocks for each sub, data.table
subjs     <- DT_blocks$subid    # sub IDs
n_subj    <- length(subjs)      # no. of subs
b_subjs   <- DT_blocks$N        # block numbers
b_max     <- max(b_subjs)       # maximal number of blocks
t_subjs   <- array(0, c(n_subj, b_max)) # trial number for each sub and block
for (i in 1:n_subj) {
subj <- subjs[i]  # current sub
b <- b_subjs[i]   # no. of blocks for the current sub.
t_subjs[i, 1:b] <- DT_trials[subid == subj]$N # no. of trials for all blocks of the current sub
}
t_max     <- max(t_subjs) # maximal no. of trials across all blocks and subs.
gen_file <- 1 #whether or not generate a data file, only generating for main analysis
general_info        <- list(subjs, n_subj, b_subjs, b_max, t_subjs, t_max,gen_file)
names(general_info) <- c("subjs", "n_subj", "b_subjs", "b_max", "t_subjs", "t_max","gen_file")
data_list <- prepro_func(data_df,general_info)  # get the data ready for stan
load('fit_m7c2.RData')
parVals <- rstan::extract(fit_m7c2, permuted = TRUE)
etar     <- parVals$etar                 # a 60000*23 matrix
etap     <- parVals$etap                # a 60000*23 matrix
tau      <- parVals$tau                # a 60000*23 matrix
etack    <- parVals$etack             # a 60000*23 matrix
tauck    <- parVals$tauck            # a 60000*23 matrix
fp       <- parVals$fp              # a 60000*23 matrix
kapa1    <- parVals[['kapa']][,,1] # a 60000*23 matrix
kapa2    <- parVals[['kapa']][,,2] # a 60000*23 matrix
kapa3    <- parVals[['kapa']][,,3] # a 60000*23 matrix
writeMat('m7c2_subwise_para_audience.mat',etar=etar,etap=etap,tau=tau,etack=etack,tauck=tauck,fp=fp,kapa1=kapa1,kapa2=kapa2,kapa3=kapa3)
